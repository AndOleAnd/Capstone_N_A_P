{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h3 # h3 bins from uber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions have been copied over from notebooks that already exist for this project. Ideally, these would be imported from a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "def create_crash_df(train_file = '../Inputs/Train.csv'):  \n",
    "    crash_df = pd.read_csv(train_file, parse_dates=['datetime'])\n",
    "    return crash_df\n",
    "\n",
    "#Creating temporal features like months, weekdays, etc.\n",
    "def create_temporal_features(df):\n",
    "    dict_windows = {1: \"00-03\", 2: \"03-06\", 3: \"06-09\", 4: \"09-12\", 5: \"12-15\", 6: \"15-18\", 7: \"18-21\", 8: \"21-24\"}\n",
    "    dict_months = {1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\",\n",
    "               7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\"}\n",
    "    df[\"time_window\"] = df[\"datetime\"].apply(lambda x: math.floor(x.hour / 3) + 1)\n",
    "    df[\"time_window_str\"] = df[\"time_window\"].apply(lambda x: dict_windows.get(x))\n",
    "    df[\"day\"] = df[\"datetime\"].apply(lambda x: x.day)\n",
    "    df[\"month\"] = df[\"datetime\"].apply(lambda x: dict_months.get(x.month))\n",
    "    df[\"year\"] = df[\"datetime\"].apply(lambda x: x.year)\n",
    "    df[\"weekday\"] = df[\"datetime\"].apply(lambda x: x.weekday())\n",
    "    return df\n",
    "\n",
    "#Exporting the dataframe back to csv\n",
    "def export_df_to_csv(df,path_file='../Inputs/train_h3.csv'):\n",
    "    df.to_csv(path_file,index=False)\n",
    "    print(f'file created {path_file}') \n",
    "\n",
    "#Joins provided data sets for road segments into one file, indicating latitude and longitude for each segment. This enables placement in h3 bins.    \n",
    "def join_segment_files(path='../Inputs/', road_surveys='Segment_info.csv',segments_geometry='segments_geometry.geojson'):\n",
    "    ''' \n",
    "        Load the survey data, Load the segment geometry, Join the two segment dfs.\n",
    "        return a combined dataframe\n",
    "    '''\n",
    "    road_surveys = pd.read_csv(path+road_surveys)\n",
    "    road_segment_locs = gpd.read_file(path+segments_geometry)\n",
    "    segments_merged = pd.merge(road_segment_locs, road_surveys, on='segment_id', how='left')\n",
    "    segments_merged[\"longitude\"] = segments_merged.geometry.centroid.x\n",
    "    segments_merged[\"latitude\"] = segments_merged.geometry.centroid.y\n",
    "    segments_merged = assign_hexbin(segments_merged)\n",
    "    return segments_merged\n",
    "\n",
    "#Defines time clusters, see docstring for more info\n",
    "def assign_TW_cluster(weekday, time_window, holiday=0, strategy='baseline'):\n",
    "    '''\n",
    "    Can be used in a lambda function to return the time window cluster for a given day and time window.\n",
    "    e.g. crash_df[\"cluster\"] = crash_df.apply(lambda x: return_TW_cluster(x.weekday, x.time_window_str) ,axis=1)\n",
    "    This is called by the function: create_cluster_feature.\n",
    "    '''\n",
    "    if strategy == 'baseline':\n",
    "        return 'baseline'\n",
    "    \n",
    "    if strategy == 'mean_shift_modified':\n",
    "        if weekday == 7:\n",
    "            return 'off_peak'        \n",
    "        elif weekday == 6:\n",
    "            return 'off_peak'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'peak'\n",
    "    \n",
    "    elif strategy == 'saturday_2':\n",
    "        if weekday == 7:\n",
    "            return 'off_peak'        \n",
    "        elif weekday == 6:\n",
    "            return 'off_peak'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'saturday_busy'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'saturday_busy'    \n",
    "    \n",
    "    elif strategy == 'holiday_7':\n",
    "        if weekday == 7:\n",
    "            return 'holiday'        \n",
    "        elif weekday == 6:\n",
    "            return 'sunday'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'saturday_busy'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'saturday_busy'      \n",
    "\n",
    "    elif strategy == 'holiday_7':\n",
    "        if weekday == 7:\n",
    "            return 'holiday'        \n",
    "        elif weekday == 6:\n",
    "            return 'sunday'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'saturday_busy'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'saturday_busy'      \n",
    "    \n",
    "\n",
    "    elif strategy == 'no_cluster':\n",
    "        return (str(weekday)+str(time_window)+str(holiday))\n",
    "\n",
    "#Creates time cluster feature in existing data frame\n",
    "def create_cluster_feature(crash_df, strategy='baseline', verbose=0):\n",
    "    '''\n",
    "    Function takes crash df and creates new column with tw cluster labels.\n",
    "    If verbose is increased, the time window clusters will be visualised.\n",
    "    '''\n",
    "    crash_df[\"cluster\"] = crash_df.apply(lambda x: \n",
    "                                         assign_TW_cluster(weekday=x.weekday,\n",
    "                                                           time_window=x.time_window_str,\n",
    "                                                           strategy=strategy) \n",
    "                                         ,axis=1)\n",
    "    \n",
    "    print(f'{crash_df.cluster.nunique()} clusters created')\n",
    "    if verbose > 1:\n",
    "        tb_clusters = sns.FacetGrid(crash_df,hue='cluster', height=5)\n",
    "        tb_clusters.map(sns.stripplot,'weekday', 'time_window_str', s=20, \n",
    "                                       order = ['00-03', '03-06', '06-09', '09-12', \n",
    "                                                '12-15', '15-18', '18-21', '21-24'],\n",
    "                                    label = 'Time Window Clusters')\n",
    "    return crash_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Identifying frequency outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take historical data but cut off \"frequency outliers\" which occurred only once in the whole data set -> [provide function to generate list of frequency outlier hex bins]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_hexbin(df,lat_column=\"latitude\",lon_column=\"longitude\", hexbin_resolution=6):\n",
    "    '''Assigning hex bins based on h3 classification and latitude and longitude'''\n",
    "    df[\"h3_zone_{}\".format(hexbin_resolution)] = df.apply(lambda x: h3.geo_to_h3(x[lat_column], x[lon_column], hexbin_resolution),axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = create_crash_df()\n",
    "df = create_temporal_features(df_raw)\n",
    "df = assign_hexbin(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 clusters created\n"
     ]
    }
   ],
   "source": [
    "df_cluster = create_cluster_feature(df, strategy='mean_shift_modified', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rta_per_cluster_and_bins(df_cluster):\n",
    "    '''Add up RTA's per hex bin and time custer'''\n",
    "    df_rta = df_cluster.groupby([df_cluster.columns[-2], \"cluster\"]).agg({\"uid\": \"count\"}).reset_index()\n",
    "    col_names = [df_rta.columns[0]] + [df_rta.columns[1]] + [\"RTA\"]\n",
    "    df_rta.columns = col_names\n",
    "    return df_rta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rta = rta_per_cluster_and_bins(df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_h3(df_hex, df_clusters):\n",
    "    '''Create list of unique hex bins times unique time clusters'''\n",
    "    return list(set(df_hex[df_hex.columns[0]])) * df_clusters[\"cluster\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_cluster_comb = get_list_of_h3(df_rta, df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_states(df_clusters, df_hex):\n",
    "    '''Create list of time clusters'''\n",
    "    states = []\n",
    "    for state in df_clusters[\"cluster\"].unique():\n",
    "        states += ([state] * df_hex[df_hex.columns[0]].nunique())\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = get_list_of_states(df_cluster, df_rta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_df(list_hex_bins, list_time_clusters):\n",
    "    '''Create an empty data frame of format hex bins * time clusters'''\n",
    "    df_empty = pd.DataFrame(data=[list_hex_bins, list_time_clusters]).T\n",
    "    df_empty.columns = [df_rta.columns[0], \"cluster\"]\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = create_empty_df(hex_cluster_comb, states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_df_hex_rta(df_empty, df_rta):\n",
    "    '''Join road traffic accidents onto empty data frame'''\n",
    "    df_merged = pd.merge(df_empty, df_rta, on=[df_empty.columns[0], df_empty.columns[1]], how=\"outer\")\n",
    "    df_filled = df_merged.fillna(0)\n",
    "    df_filled = df_filled.sort_values(by=[df_empty.columns[0], df_empty.columns[1]])\n",
    "    return df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = fill_df_hex_rta(df_empty, df_rta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_pred_input_df(df_hex_bins):\n",
    "    '''Based on hex bin resolution creates an empty data frame for each 3 hour time window for each hex bin.\n",
    "     This results in a n * 2 dataframe (columns: time_windows, hex_bins) where number of rows equals hex_bins * 4369.\n",
    "     4369 is the result of days between start and end date (in days) * 8 time windows per day (24 / 3 hours)'''\n",
    "    #Create dataframe to get the accurate amount of 3-hour time windows for the desired time frame\n",
    "    date_start = '2018-01-01'\n",
    "    date_end = '2019-07-01'\n",
    "    dates = pd.date_range(date_start, date_end, freq='3h')\n",
    "    all_days_df = pd.DataFrame(dates, columns=[\"dates\"])\n",
    "\n",
    "    time_windows = list(all_days_df[\"dates\"])\n",
    "    len_windows = all_days_df.shape[0]\n",
    "    list_unique_hexbins = df_hex_bins[df_hex_bins.columns[0]].unique()\n",
    "    \n",
    "    list_bins_per_window = []\n",
    "    list_time_windows = []\n",
    "    \n",
    "    for i in range(0, len(list_unique_hexbins)):\n",
    "        list_bins_per_window += len_windows * [list_unique_hexbins[i]]\n",
    "        list_time_windows += time_windows\n",
    "        \n",
    "    input_df = {\"time_windows\": list_time_windows, \"hex_bins\": list_bins_per_window}\n",
    "    df_pred_template = pd.DataFrame(data=input_df)\n",
    "    \n",
    "    return df_pred_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_pred = create_raw_pred_input_df(df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_pred[\"time_window_key\"] = df_raw_pred[\"time_windows\"].apply(lambda x: str(x.year) + \"-\" + str(x.month) + \"-\" + str(x.day) + \"-\" + str(math.floor(x.hour / 3)))\n",
    "df_cluster[\"time_window_key\"] = df_cluster[\"datetime\"].apply(lambda x: str(x.year) + \"-\" + str(x.month) + \"-\" + str(x.day) + \"-\" + str(math.floor(x.hour / 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rta_per_time_window(df_cluster):\n",
    "    '''Add up RTA's per time window'''\n",
    "    df_tw = df_cluster.groupby([\"time_window_key\", \"h3_zone_6\"]).agg({\"uid\": \"count\"}).reset_index()\n",
    "    col_names = [\"time_window_key\"] + [\"hex_bins\"] + [\"RTA\"]\n",
    "    df_tw.columns = col_names\n",
    "    return df_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw = rta_per_time_window(df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_overall_df(df_raw_pred, df_rta_per_tw):\n",
    "    '''Join road traffic accidents onto empty data frame that consists of time windows (8 per day) for all days (1.5 years) for all hex bins. \n",
    "    For combinations with no accidents, NaNs will be converted into 0.'''\n",
    "    df_merged = pd.merge(df_raw_pred, df_rta_per_tw, on=[\"time_window_key\", \"hex_bins\"], how=\"outer\")\n",
    "    df_merged = df_merged.fillna(0)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_filled = fill_overall_df(df_raw_pred, df_tw)\n",
    "\n",
    "list_of_c = list(df_raw_filled.columns)\n",
    "list_of_c[0] = \"datetime\"\n",
    "df_raw_filled.columns = list_of_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_filled = create_temporal_features(df_raw_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 clusters created\n"
     ]
    }
   ],
   "source": [
    "df_final = create_cluster_feature(df_raw_filled, strategy='mean_shift_modified', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = df_final.groupby(\"hex_bins\")\n",
    "df_classes = df_classes.agg({'RTA': [np.mean, np.std, np.sum, np.count_nonzero]})\n",
    "df_classes = df_classes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes.columns = [\"hex_bins\", \"RTA_mean\", \"RTA_std\", \"RTA_sum\", \"RTA_nonzero\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq_outliers = df_classes.loc[df_classes[\"RTA_nonzero\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_freq_outliers = df_freq_outliers[\"hex_bins\"].values\n",
    "#list(list_freq_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Using RTA frequency as a prediction measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each hex bin, use the frequencies (sum of occurrences, not the magnitude) for each time window as a prediction value -> [provide function to generate data frame of 56 (3 hour) time windows for each hex bin]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>hex_bins</th>\n",
       "      <th>time_window_key</th>\n",
       "      <th>RTA</th>\n",
       "      <th>time_window</th>\n",
       "      <th>time_window_str</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>00-03</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>03-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>09-12</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime         hex_bins time_window_key  RTA  time_window  \\\n",
       "0 2018-01-01 00:00:00  867a44a6fffffff      2018-1-1-0  0.0            1   \n",
       "1 2018-01-01 03:00:00  867a44a6fffffff      2018-1-1-1  0.0            2   \n",
       "2 2018-01-01 06:00:00  867a44a6fffffff      2018-1-1-2  0.0            3   \n",
       "3 2018-01-01 09:00:00  867a44a6fffffff      2018-1-1-3  0.0            4   \n",
       "4 2018-01-01 12:00:00  867a44a6fffffff      2018-1-1-4  0.0            5   \n",
       "\n",
       "  time_window_str  day month  year  weekday   cluster  \n",
       "0           00-03    1   Jan  2018        0  off_peak  \n",
       "1           03-06    1   Jan  2018        0  off_peak  \n",
       "2           06-09    1   Jan  2018        0      peak  \n",
       "3           09-12    1   Jan  2018        0    middle  \n",
       "4           12-15    1   Jan  2018        0    middle  "
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq = df_final.groupby([\"hex_bins\", \"weekday\", \"time_window_str\"])\n",
    "df_freq = df_freq.agg({'RTA': [np.mean, np.std, np.sum, np.count_nonzero]})\n",
    "df_freq = df_freq.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6552"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "117 * 7 * 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_freq.head(56)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(6552, 7)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq_filtered = df_freq.loc[~df_freq[\"hex_bins\"].isin(list_of_bins)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq_filtered.shape\n",
    "df_freq_filtered.columns = [\"hex_bins\", \"weekday\", \"time_window\", \"RTA_mean\", \"RTA_std\", \"RTA_sum\", \"RTA_freq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_bins</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time_window</th>\n",
       "      <th>RTA_mean</th>\n",
       "      <th>RTA_std</th>\n",
       "      <th>RTA_sum</th>\n",
       "      <th>RTA_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>00-03</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>03-06</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>06-09</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>09-12</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>12-15</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hex_bins  weekday time_window  RTA_mean  RTA_std  RTA_sum  RTA_freq\n",
       "0  867a44a6fffffff        0       00-03       0.0      0.0      0.0       0.0\n",
       "1  867a44a6fffffff        0       03-06       0.0      0.0      0.0       0.0\n",
       "2  867a44a6fffffff        0       06-09       0.0      0.0      0.0       0.0\n",
       "3  867a44a6fffffff        0       09-12       0.0      0.0      0.0       0.0\n",
       "4  867a44a6fffffff        0       12-15       0.0      0.0      0.0       0.0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weekday</th>\n",
       "      <th>RTA_mean</th>\n",
       "      <th>RTA_std</th>\n",
       "      <th>RTA_sum</th>\n",
       "      <th>RTA_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "      <td>4032.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.019934</td>\n",
       "      <td>0.089871</td>\n",
       "      <td>1.555060</td>\n",
       "      <td>1.048363</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>2.000248</td>\n",
       "      <td>0.060241</td>\n",
       "      <td>0.219307</td>\n",
       "      <td>4.699287</td>\n",
       "      <td>2.694370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>5.000000</td>\n",
       "      <td>0.012821</td>\n",
       "      <td>0.113228</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.846154</td>\n",
       "      <td>4.463192</td>\n",
       "      <td>66.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           weekday     RTA_mean      RTA_std      RTA_sum     RTA_freq\n",
       "count  4032.000000  4032.000000  4032.000000  4032.000000  4032.000000\n",
       "mean      3.000000     0.019934     0.089871     1.555060     1.048363\n",
       "std       2.000248     0.060241     0.219307     4.699287     2.694370\n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000\n",
       "25%       1.000000     0.000000     0.000000     0.000000     0.000000\n",
       "50%       3.000000     0.000000     0.000000     0.000000     0.000000\n",
       "75%       5.000000     0.012821     0.113228     1.000000     1.000000\n",
       "max       6.000000     0.846154     4.463192    66.000000    37.000000"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_filtered.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_freq_filtered.groupby(\"hex_bins\").RTA_freq.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file created ../Inputs/predictions_freq.csv\n"
     ]
    }
   ],
   "source": [
    "export_df_to_csv(df_freq,path_file='../Inputs/predictions_freq.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "file created ../Inputs/predictions_freq_h3_filtered.csv\n"
     ]
    }
   ],
   "source": [
    "export_df_to_csv(df_freq_filtered,path_file='../Inputs/predictions_freq_h3_filtered.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Using weather data to predict RTA occurrence (yes/no?) per time window and hex_bin class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Add weather data (data per time window) to B, also fit regression model on weather data for two different \"classes\" of hex bins (dangerous, not so dangerous) [provide code that can output a probability of there being an accident (classification) for each hex bin in each time window (Note: These will still be the same for all hex bins of a class)]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Using weather data and traffic speed data to predict RTA occurrence (yes/no?) per time window and hex_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend C to also include data that is specific per time window and hex bin. This allows the regression model to output a different value for each time window and hex bin (not only hex bin class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test Area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_of_bins = ['867a45067ffffff',\n",
    " '867a45077ffffff',\n",
    " '867a4511fffffff',\n",
    " '867a4512fffffff',\n",
    " '867a45147ffffff',\n",
    " '867a4515fffffff',\n",
    " '867a45177ffffff',\n",
    " '867a45817ffffff',\n",
    " '867a4584fffffff',\n",
    " '867a4585fffffff',\n",
    " '867a458dfffffff',\n",
    " '867a458f7ffffff',\n",
    " '867a45a8fffffff',\n",
    " '867a45b0fffffff',\n",
    " '867a45b17ffffff',\n",
    " '867a45b67ffffff',\n",
    " '867a45b77ffffff',\n",
    " '867a6141fffffff',\n",
    " '867a614d7ffffff',\n",
    " '867a616b7ffffff',\n",
    " '867a6304fffffff',\n",
    " '867a632a7ffffff',\n",
    " '867a63307ffffff',\n",
    " '867a6331fffffff',\n",
    " '867a6360fffffff',\n",
    " '867a63667ffffff',\n",
    " '867a6396fffffff',\n",
    " '867a656c7ffffff',\n",
    " '867a65797ffffff',\n",
    " '867a6e18fffffff',\n",
    " '867a6e1b7ffffff',\n",
    " '867a6e4c7ffffff',\n",
    " '867a6e517ffffff',\n",
    " '867a6e59fffffff',\n",
    " '867a6e5a7ffffff',\n",
    " '867a6e5b7ffffff',\n",
    " '867a6e657ffffff',\n",
    " '867a6e737ffffff',\n",
    " '867a6e797ffffff',\n",
    " '867a6e79fffffff',\n",
    " '867a6e7b7ffffff',\n",
    " '867a6ecf7ffffff',\n",
    " '867a6ed47ffffff',\n",
    " '867a6ed97ffffff','867a6eda7ffffff']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(list_of_bins)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df_to_csv(df,path_file='../Inputs/h3_excluded.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nairobi_ambulance] *",
   "language": "python",
   "name": "conda-env-nairobi_ambulance-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
