{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import pandas as pd \n",
    "import geopandas as gpd\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import h3 # h3 bins from uber"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These functions have been copied over from notebooks that already exist for this project. Ideally, these would be imported from a module."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading the data\n",
    "def create_crash_df(train_file = '../Inputs/Train.csv'):  \n",
    "    crash_df = pd.read_csv(train_file, parse_dates=['datetime'])\n",
    "    return crash_df\n",
    "\n",
    "#Creating temporal features like months, weekdays, etc.\n",
    "def create_temporal_features(df):\n",
    "    dict_windows = {1: \"00-03\", 2: \"03-06\", 3: \"06-09\", 4: \"09-12\", 5: \"12-15\", 6: \"15-18\", 7: \"18-21\", 8: \"21-24\"}\n",
    "    dict_months = {1: \"Jan\", 2: \"Feb\", 3: \"Mar\", 4: \"Apr\", 5: \"May\", 6: \"Jun\",\n",
    "               7: \"Jul\", 8: \"Aug\", 9: \"Sep\", 10: \"Oct\", 11: \"Nov\", 12: \"Dec\"}\n",
    "    df[\"time_window\"] = df[\"datetime\"].apply(lambda x: math.floor(x.hour / 3) + 1)\n",
    "    df[\"time_window_str\"] = df[\"time_window\"].apply(lambda x: dict_windows.get(x))\n",
    "    df[\"day\"] = df[\"datetime\"].apply(lambda x: x.day)\n",
    "    df[\"month\"] = df[\"datetime\"].apply(lambda x: dict_months.get(x.month))\n",
    "    df[\"year\"] = df[\"datetime\"].apply(lambda x: x.year)\n",
    "    df[\"weekday\"] = df[\"datetime\"].apply(lambda x: x.weekday())\n",
    "    return df\n",
    "\n",
    "#Exporting the dataframe back to csv\n",
    "def export_df_to_csv(df,path_file='../Inputs/train_h3.csv'):\n",
    "    df.to_csv(path_file,index=False)\n",
    "    print(f'file created {path_file}') \n",
    "\n",
    "#Joins provided data sets for road segments into one file, indicating latitude and longitude for each segment. This enables placement in h3 bins.    \n",
    "def join_segment_files(path='../Inputs/', road_surveys='Segment_info.csv',segments_geometry='segments_geometry.geojson'):\n",
    "    ''' \n",
    "        Load the survey data, Load the segment geometry, Join the two segment dfs.\n",
    "        return a combined dataframe\n",
    "    '''\n",
    "    road_surveys = pd.read_csv(path+road_surveys)\n",
    "    road_segment_locs = gpd.read_file(path+segments_geometry)\n",
    "    segments_merged = pd.merge(road_segment_locs, road_surveys, on='segment_id', how='left')\n",
    "    segments_merged[\"longitude\"] = segments_merged.geometry.centroid.x\n",
    "    segments_merged[\"latitude\"] = segments_merged.geometry.centroid.y\n",
    "    segments_merged = assign_hexbin(segments_merged)\n",
    "    return segments_merged\n",
    "\n",
    "#Defines time clusters, see docstring for more info\n",
    "def assign_TW_cluster(weekday, time_window, holiday=0, strategy='baseline'):\n",
    "    '''\n",
    "    Can be used in a lambda function to return the time window cluster for a given day and time window.\n",
    "    e.g. crash_df[\"cluster\"] = crash_df.apply(lambda x: return_TW_cluster(x.weekday, x.time_window_str) ,axis=1)\n",
    "    This is called by the function: create_cluster_feature.\n",
    "    '''\n",
    "    if strategy == 'baseline':\n",
    "        return 'baseline'\n",
    "    \n",
    "    if strategy == 'mean_shift_modified':\n",
    "        if weekday == 7:\n",
    "            return 'off_peak'        \n",
    "        elif weekday == 6:\n",
    "            return 'off_peak'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'peak'\n",
    "    \n",
    "    elif strategy == 'saturday_2':\n",
    "        if weekday == 7:\n",
    "            return 'off_peak'        \n",
    "        elif weekday == 6:\n",
    "            return 'off_peak'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'saturday_busy'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'saturday_busy'    \n",
    "    \n",
    "    elif strategy == 'holiday_7':\n",
    "        if weekday == 7:\n",
    "            return 'holiday'        \n",
    "        elif weekday == 6:\n",
    "            return 'sunday'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'saturday_busy'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'saturday_busy'      \n",
    "\n",
    "    elif strategy == 'holiday_7':\n",
    "        if weekday == 7:\n",
    "            return 'holiday'        \n",
    "        elif weekday == 6:\n",
    "            return 'sunday'\n",
    "        elif weekday in [0,1,2,3,4]:\n",
    "            if time_window in [\"06-09\"]:\n",
    "                return 'peak'\n",
    "            elif time_window in [\"09-12\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'middle'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'    \n",
    "        elif weekday == 5:\n",
    "            if time_window in [\"06-09\", \"12-15\", \"15-18\", \"18-21\"]:\n",
    "                return 'saturday_busy'\n",
    "            elif time_window in [\"00-03\", \"03-06\", \"21-24\"]:\n",
    "                return 'off_peak'\n",
    "            elif time_window in [\"09-12\"]:\n",
    "                return 'saturday_busy'      \n",
    "    \n",
    "\n",
    "    elif strategy == 'no_cluster':\n",
    "        return (str(weekday)+str(time_window)+str(holiday))\n",
    "\n",
    "#Creates time cluster feature in existing data frame\n",
    "def create_cluster_feature(crash_df, strategy='baseline', verbose=0):\n",
    "    '''\n",
    "    Function takes crash df and creates new column with tw cluster labels.\n",
    "    If verbose is increased, the time window clusters will be visualised.\n",
    "    '''\n",
    "    crash_df[\"cluster\"] = crash_df.apply(lambda x: \n",
    "                                         assign_TW_cluster(weekday=x.weekday,\n",
    "                                                           time_window=x.time_window_str,\n",
    "                                                           strategy=strategy) \n",
    "                                         ,axis=1)\n",
    "    \n",
    "    print(f'{crash_df.cluster.nunique()} clusters created')\n",
    "    if verbose > 1:\n",
    "        tb_clusters = sns.FacetGrid(crash_df,hue='cluster', height=5)\n",
    "        tb_clusters.map(sns.stripplot,'weekday', 'time_window_str', s=20, \n",
    "                                       order = ['00-03', '03-06', '06-09', '09-12', \n",
    "                                                '12-15', '15-18', '18-21', '21-24'],\n",
    "                                    label = 'Time Window Clusters')\n",
    "    return crash_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## A. Identifying frequency outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take historical data but cut off \"frequency outliers\" which occurred only once in the whole data set -> [provide function to generate list of frequency outlier hex bins]."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_hexbin(df,lat_column=\"latitude\",lon_column=\"longitude\", hexbin_resolution=6):\n",
    "    '''Assigning hex bins based on h3 classification and latitude and longitude'''\n",
    "    df[\"h3_zone_{}\".format(hexbin_resolution)] = df.apply(lambda x: h3.geo_to_h3(x[lat_column], x[lon_column], hexbin_resolution),axis=1)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw = create_crash_df()\n",
    "df = create_temporal_features(df_raw)\n",
    "df = assign_hexbin(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 clusters created\n"
     ]
    }
   ],
   "source": [
    "df_cluster = create_cluster_feature(df, strategy='mean_shift_modified', verbose=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rta_per_cluster_and_bins(df_cluster):\n",
    "    '''Add up RTA's per hex bin and time custer'''\n",
    "    df_rta = df_cluster.groupby([df_cluster.columns[-2], \"cluster\"]).agg({\"uid\": \"count\"}).reset_index()\n",
    "    col_names = [df_rta.columns[0]] + [df_rta.columns[1]] + [\"RTA\"]\n",
    "    df_rta.columns = col_names\n",
    "    return df_rta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_rta = rta_per_cluster_and_bins(df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_h3(df_hex, df_clusters):\n",
    "    '''Create list of unique hex bins times unique time clusters'''\n",
    "    return list(set(df_hex[df_hex.columns[0]])) * df_clusters[\"cluster\"].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "hex_cluster_comb = get_list_of_h3(df_rta, df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_list_of_states(df_clusters, df_hex):\n",
    "    '''Create list of time clusters'''\n",
    "    states = []\n",
    "    for state in df_clusters[\"cluster\"].unique():\n",
    "        states += ([state] * df_hex[df_hex.columns[0]].nunique())\n",
    "    return states"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "states = get_list_of_states(df_cluster, df_rta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_empty_df(list_hex_bins, list_time_clusters):\n",
    "    '''Create an empty data frame of format hex bins * time clusters'''\n",
    "    df_empty = pd.DataFrame(data=[list_hex_bins, list_time_clusters]).T\n",
    "    df_empty.columns = [df_rta.columns[0], \"cluster\"]\n",
    "    return df_empty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_empty = create_empty_df(hex_cluster_comb, states)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_df_hex_rta(df_empty, df_rta):\n",
    "    '''Join road traffic accidents onto empty data frame'''\n",
    "    df_merged = pd.merge(df_empty, df_rta, on=[df_empty.columns[0], df_empty.columns[1]], how=\"outer\")\n",
    "    df_filled = df_merged.fillna(0)\n",
    "    df_filled = df_filled.sort_values(by=[df_empty.columns[0], df_empty.columns[1]])\n",
    "    return df_filled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_filled = fill_df_hex_rta(df_empty, df_rta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_raw_pred_input_df(df_hex_bins):\n",
    "    '''Based on hex bin resolution creates an empty data frame for each 3 hour time window for each hex bin.\n",
    "     This results in a n * 2 dataframe (columns: time_windows, hex_bins) where number of rows equals hex_bins * 4369.\n",
    "     4369 is the result of days between start and end date (in days) * 8 time windows per day (24 / 3 hours)'''\n",
    "    #Create dataframe to get the accurate amount of 3-hour time windows for the desired time frame\n",
    "    date_start = '2018-01-01'\n",
    "    date_end = '2019-07-01'\n",
    "    dates = pd.date_range(date_start, date_end, freq='3h')\n",
    "    all_days_df = pd.DataFrame(dates, columns=[\"dates\"])\n",
    "\n",
    "    time_windows = list(all_days_df[\"dates\"])\n",
    "    len_windows = all_days_df.shape[0]\n",
    "    list_unique_hexbins = df_hex_bins[df_hex_bins.columns[0]].unique()\n",
    "    \n",
    "    list_bins_per_window = []\n",
    "    list_time_windows = []\n",
    "    \n",
    "    for i in range(0, len(list_unique_hexbins)):\n",
    "        list_bins_per_window += len_windows * [list_unique_hexbins[i]]\n",
    "        list_time_windows += time_windows\n",
    "        \n",
    "    input_df = {\"time_windows\": list_time_windows, \"hex_bins\": list_bins_per_window}\n",
    "    df_pred_template = pd.DataFrame(data=input_df)\n",
    "    \n",
    "    return df_pred_template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_pred = create_raw_pred_input_df(df_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_pred[\"time_window_key\"] = df_raw_pred[\"time_windows\"].apply(lambda x: str(x.year) + \"-\" + str(x.month) + \"-\" + str(x.day) + \"-\" + str(math.floor(x.hour / 3)))\n",
    "df_cluster[\"time_window_key\"] = df_cluster[\"datetime\"].apply(lambda x: str(x.year) + \"-\" + str(x.month) + \"-\" + str(x.day) + \"-\" + str(math.floor(x.hour / 3)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rta_per_time_window(df_cluster):\n",
    "    '''Add up RTA's per time window'''\n",
    "    df_tw = df_cluster.groupby([\"time_window_key\", \"h3_zone_6\"]).agg({\"uid\": \"count\"}).reset_index()\n",
    "    col_names = [\"time_window_key\"] + [\"hex_bins\"] + [\"RTA\"]\n",
    "    df_tw.columns = col_names\n",
    "    return df_tw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tw = rta_per_time_window(df_cluster)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**New helper function**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fill_overall_df(df_raw_pred, df_rta_per_tw):\n",
    "    '''Join road traffic accidents onto empty data frame that consists of time windows (8 per day) for all days (1.5 years) for all hex bins. \n",
    "    For combinations with no accidents, NaNs will be converted into 0.'''\n",
    "    df_merged = pd.merge(df_raw_pred, df_rta_per_tw, on=[\"time_window_key\", \"hex_bins\"], how=\"outer\")\n",
    "    df_merged = df_merged.fillna(0)\n",
    "    return df_merged"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_filled = fill_overall_df(df_raw_pred, df_tw)\n",
    "\n",
    "list_of_c = list(df_raw_filled.columns)\n",
    "list_of_c[0] = \"datetime\"\n",
    "df_raw_filled.columns = list_of_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_raw_filled = create_temporal_features(df_raw_filled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3 clusters created\n"
     ]
    }
   ],
   "source": [
    "df_final = create_cluster_feature(df_raw_filled, strategy='mean_shift_modified', verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes = df_final.groupby(\"hex_bins\")\n",
    "df_classes = df_classes.agg({'RTA': [np.mean, np.std, np.sum, np.count_nonzero]})\n",
    "df_classes = df_classes.reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_classes.columns = [\"hex_bins\", \"RTA_mean\", \"RTA_std\", \"RTA_sum\", \"RTA_nonzero\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq_outliers = df_classes.loc[df_classes[\"RTA_nonzero\"] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_freq_outliers = df_freq_outliers[\"hex_bins\"].values\n",
    "#list(list_freq_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['867a45067ffffff', '867a45077ffffff', '867a4511fffffff',\n",
       "       '867a4512fffffff', '867a45147ffffff', '867a4515fffffff',\n",
       "       '867a45177ffffff', '867a45817ffffff', '867a4584fffffff',\n",
       "       '867a4585fffffff', '867a458dfffffff', '867a458f7ffffff',\n",
       "       '867a45a8fffffff', '867a45b0fffffff', '867a45b17ffffff',\n",
       "       '867a45b67ffffff', '867a45b77ffffff', '867a6141fffffff',\n",
       "       '867a614d7ffffff', '867a616b7ffffff', '867a6304fffffff',\n",
       "       '867a632a7ffffff', '867a63307ffffff', '867a6331fffffff',\n",
       "       '867a6360fffffff', '867a63667ffffff', '867a6396fffffff',\n",
       "       '867a656c7ffffff', '867a65797ffffff', '867a6e18fffffff',\n",
       "       '867a6e1b7ffffff', '867a6e4c7ffffff', '867a6e517ffffff',\n",
       "       '867a6e59fffffff', '867a6e5a7ffffff', '867a6e5b7ffffff',\n",
       "       '867a6e657ffffff', '867a6e737ffffff', '867a6e797ffffff',\n",
       "       '867a6e79fffffff', '867a6e7b7ffffff', '867a6ecf7ffffff',\n",
       "       '867a6ed47ffffff', '867a6ed97ffffff', '867a6eda7ffffff'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list_freq_outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Output the list of hex bins to exclude in a .csv file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## B. Using RTA frequency as a prediction measure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each hex bin, use the frequencies (sum of occurrences, not the magnitude) for each time window as a prediction value -> [provide function to generate data frame of 56 (3 hour) time windows for each hex bin]."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>hex_bins</th>\n",
       "      <th>time_window_key</th>\n",
       "      <th>RTA</th>\n",
       "      <th>time_window</th>\n",
       "      <th>time_window_str</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "      <td>00-03</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 03:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>03-06</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 06:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-2</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "      <td>06-09</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 09:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-3</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>09-12</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 12:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2018-1-1-4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12-15</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime         hex_bins time_window_key  RTA  time_window  \\\n",
       "0 2018-01-01 00:00:00  867a44a6fffffff      2018-1-1-0  0.0            1   \n",
       "1 2018-01-01 03:00:00  867a44a6fffffff      2018-1-1-1  0.0            2   \n",
       "2 2018-01-01 06:00:00  867a44a6fffffff      2018-1-1-2  0.0            3   \n",
       "3 2018-01-01 09:00:00  867a44a6fffffff      2018-1-1-3  0.0            4   \n",
       "4 2018-01-01 12:00:00  867a44a6fffffff      2018-1-1-4  0.0            5   \n",
       "\n",
       "  time_window_str  day month  year  weekday   cluster  \n",
       "0           00-03    1   Jan  2018        0  off_peak  \n",
       "1           03-06    1   Jan  2018        0  off_peak  \n",
       "2           06-09    1   Jan  2018        0      peak  \n",
       "3           09-12    1   Jan  2018        0    middle  \n",
       "4           12-15    1   Jan  2018        0    middle  "
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(511173, 11)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_hex_bins(df, list_hex_bins):\n",
    "    \"\"\"Filter out all hex bins on the list and reduce data frame to non-zero values\"\"\"\n",
    "    \n",
    "    # Filters overall dataframe to exclude hex bins with only one RTA occurrence in the whole timeframe (according to input list)\n",
    "    df_freq_filtered = df.loc[~df[\"hex_bins\"].isin(list_hex_bins)]\n",
    "    \n",
    "    # Also filters out all hex bin and time window combinations where no RTA occurred\n",
    "    df_freq_filtered = df_freq_filtered.loc[df_freq_filtered[\"RTA\"] > 0]\n",
    "    \n",
    "    return df_freq_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_freq_filtered = filter_hex_bins(df_final, list_freq_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4227, 11)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_filtered.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>hex_bins</th>\n",
       "      <th>time_window_key</th>\n",
       "      <th>RTA</th>\n",
       "      <th>time_window</th>\n",
       "      <th>time_window_str</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>year</th>\n",
       "      <th>weekday</th>\n",
       "      <th>cluster</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3514</th>\n",
       "      <td>2019-03-16 06:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2019-3-16-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>06-09</td>\n",
       "      <td>16</td>\n",
       "      <td>Mar</td>\n",
       "      <td>2019</td>\n",
       "      <td>5</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4196</th>\n",
       "      <td>2019-06-09 12:00:00</td>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>2019-6-9-4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>5</td>\n",
       "      <td>12-15</td>\n",
       "      <td>9</td>\n",
       "      <td>Jun</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5678</th>\n",
       "      <td>2018-06-13 15:00:00</td>\n",
       "      <td>867a44b5fffffff</td>\n",
       "      <td>2018-6-13-5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>6</td>\n",
       "      <td>15-18</td>\n",
       "      <td>13</td>\n",
       "      <td>Jun</td>\n",
       "      <td>2018</td>\n",
       "      <td>2</td>\n",
       "      <td>middle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8291</th>\n",
       "      <td>2019-05-06 06:00:00</td>\n",
       "      <td>867a44b5fffffff</td>\n",
       "      <td>2019-5-6-2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>06-09</td>\n",
       "      <td>6</td>\n",
       "      <td>May</td>\n",
       "      <td>2019</td>\n",
       "      <td>0</td>\n",
       "      <td>peak</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17476</th>\n",
       "      <td>2018-01-01 00:00:00</td>\n",
       "      <td>867a45107ffffff</td>\n",
       "      <td>2018-1-1-0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>00-03</td>\n",
       "      <td>1</td>\n",
       "      <td>Jan</td>\n",
       "      <td>2018</td>\n",
       "      <td>0</td>\n",
       "      <td>off_peak</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 datetime         hex_bins time_window_key  RTA  time_window  \\\n",
       "3514  2019-03-16 06:00:00  867a44a6fffffff     2019-3-16-2  1.0            3   \n",
       "4196  2019-06-09 12:00:00  867a44a6fffffff      2019-6-9-4  1.0            5   \n",
       "5678  2018-06-13 15:00:00  867a44b5fffffff     2018-6-13-5  1.0            6   \n",
       "8291  2019-05-06 06:00:00  867a44b5fffffff      2019-5-6-2  1.0            3   \n",
       "17476 2018-01-01 00:00:00  867a45107ffffff      2018-1-1-0  2.0            1   \n",
       "\n",
       "      time_window_str  day month  year  weekday   cluster  \n",
       "3514            06-09   16   Mar  2019        5    middle  \n",
       "4196            12-15    9   Jun  2019        6  off_peak  \n",
       "5678            15-18   13   Jun  2018        2    middle  \n",
       "8291            06-09    6   May  2019        0      peak  \n",
       "17476           00-03    1   Jan  2018        0  off_peak  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_filtered.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_freq_filtered.hex_bins.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_predictions(df):\n",
    "    \"\"\"Dropping all redundant rows, fixing indices and making sure the time windows are hit.\"\"\"\n",
    "\n",
    "    # Remove some redundant rows and fix indices\n",
    "    df_predictions = df.drop([\"time_window_key\", \"time_window\", \"RTA\", \"time_window_str\", \"cluster\",\n",
    "                                                             \"day\", \"month\", \"year\", \"weekday\"], axis=1)\n",
    "    df_predictions = df_predictions.reset_index()\n",
    "    df_predictions.drop(\"index\", axis=1, inplace=True)\n",
    "    \n",
    "    # Add 1 minute to have the RTA's lie inside the time window rather than on the verge, sort values and reset the index\n",
    "    df_predictions[\"datetime\"] = df_predictions[\"datetime\"].apply(lambda x: x + pd.Timedelta(minutes=1))\n",
    "    df_predictions = df_predictions.sort_values(by=\"datetime\").reset_index()\n",
    "    \n",
    "    # Drop redundant columns\n",
    "    df_predictions = df_predictions.drop(\"index\", axis=1)\n",
    "    \n",
    "    return df_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_for_clustering_b = make_predictions(df_freq_filtered)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>datetime</th>\n",
       "      <th>hex_bins</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>867a6e417ffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018-01-01 00:01:00</td>\n",
       "      <td>867a45107ffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018-01-01 03:01:00</td>\n",
       "      <td>867a6e417ffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-01-01 03:01:00</td>\n",
       "      <td>867a6e42fffffff</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018-01-01 03:01:00</td>\n",
       "      <td>867a45107ffffff</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             datetime         hex_bins\n",
       "0 2018-01-01 00:01:00  867a6e417ffffff\n",
       "1 2018-01-01 00:01:00  867a45107ffffff\n",
       "2 2018-01-01 03:01:00  867a6e417ffffff\n",
       "3 2018-01-01 03:01:00  867a6e42fffffff\n",
       "4 2018-01-01 03:01:00  867a45107ffffff"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_clustering_b.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_for_clustering_b.hex_bins.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df_to_csv(predictions_for_clustering_b,path_file='../Inputs/predictions_for_clustering_b.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## C. Using weather data to predict RTA occurrence (yes/no?) per time window and hex_bin class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adds weather data (data per day) to B and fits a regression model on this weather data for all hex bins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_freq_per_tw(df, list_freq_outliers):\n",
    "    \"\"\"Creates a sort of distribution from which hex bin and time window combinations are drawn, subject to the predicted RTA's per day\"\"\"\n",
    "    \n",
    "    # Filtering for hex bins with only one occurrence\n",
    "    df_filter = df.loc[~df[\"hex_bins\"].isin(list_freq_outliers)]\n",
    "    \n",
    "    # asdadad\n",
    "    df_freq = df_filter.groupby([\"hex_bins\", \"weekday\", \"time_window_str\"])\n",
    "    df_rta_freq = df_freq.agg({'RTA': [np.count_nonzero]})\n",
    "    df_rta_freq = df_rta_freq.reset_index()\n",
    "    df_rta_freq.columns = [\"hex_bins\", \"weekday\", \"time_window\", \"RTA_freq\"]\n",
    "    \n",
    "    return df_rta_freq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cleaned = create_freq_per_tw(df_final, list_freq_outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>hex_bins</th>\n",
       "      <th>weekday</th>\n",
       "      <th>time_window</th>\n",
       "      <th>RTA_freq</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>00-03</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>03-06</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>06-09</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>09-12</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>867a44a6fffffff</td>\n",
       "      <td>0</td>\n",
       "      <td>12-15</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          hex_bins  weekday time_window  RTA_freq\n",
       "0  867a44a6fffffff        0       00-03       0.0\n",
       "1  867a44a6fffffff        0       03-06       0.0\n",
       "2  867a44a6fffffff        0       06-09       0.0\n",
       "3  867a44a6fffffff        0       09-12       0.0\n",
       "4  867a44a6fffffff        0       12-15       0.0"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4032, 4)"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_cleaned.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Still need to get the Predictions from Andreas in here**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sample to showcase POC\n",
    "predicted_rta = [12, 23, 11, 15, 9 ,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_predictions(df, predicted_rta):\n",
    "    \"\"\"Takes a dataframe containing the RTA frequency per weekday and time window and the predicted RTA's per day and turns this into a prediction dataframe.\"\"\"\n",
    "\n",
    "    df_monday = df.loc[df[\"weekday\"] == 0].sort_values(by=\"RTA_freq\", ascending=False)\n",
    "    df_tuesday = df.loc[df[\"weekday\"] == 1].sort_values(by=\"RTA_freq\", ascending=False)\n",
    "    df_wednesday = df.loc[df[\"weekday\"] == 2].sort_values(by=\"RTA_freq\", ascending=False)\n",
    "    df_thursday = df.loc[df[\"weekday\"] == 3].sort_values(by=\"RTA_freq\", ascending=False)\n",
    "    df_friday = df.loc[df[\"weekday\"] == 4].sort_values(by=\"RTA_freq\", ascending=False)\n",
    "    df_saturday = df.loc[df[\"weekday\"] == 5].sort_values(by=\"RTA_freq\", ascending=False)\n",
    "    df_sunday = df.loc[df[\"weekday\"] == 6].sort_values(by=\"RTA_freq\", ascending=False)\n",
    "    \n",
    "    # Split overall predictions into predictions per weekday\n",
    "    lst_mon = predicted_rta[0::7]\n",
    "    lst_tue = predicted_rta[1::7]\n",
    "    lst_wed = predicted_rta[2::7]\n",
    "    lst_thu = predicted_rta[3::7]\n",
    "    lst_fri = predicted_rta[4::7]\n",
    "    lst_sat = predicted_rta[5::7]\n",
    "    lst_sun = predicted_rta[6::7]\n",
    "    \n",
    "    # The evaluation period 2019-07-01 to 2019-12-31 conveniently starts with a Monday but end with a Tuesday - hence the loop has to run \n",
    "    # one iteration more for Monday and Tuesday.\n",
    "    # This generates a list of lists of predictions for each weekday\n",
    "\n",
    "    monday_bins = tuesday_bins = wednesday_bins = thursday_bins = friday_bins = saturday_bins = sunday_bins = []\n",
    "    monday_tw = tuesday_tw = wednesday_tw = thursday_tw = friday_tw = saturday_tw = sunday_tw = []\n",
    "    \n",
    "    for i in range(len(lst_mon)):\n",
    "        monday_bins.append(list(*[df_monday[\"hex_bins\"][0:lst_mon[i]]]))\n",
    "        monday_tw.append(list(*[df_monday[\"time_window\"][0:lst_mon[i]]]))\n",
    "        tuesday_bins.append(list(*[df_tuesday[\"hex_bins\"][0:lst_tue[i]]]))\n",
    "        tuesday_tw.append(list(*[df_tuesday[\"time_window\"][0:lst_tue[i]]]))\n",
    "    for i in range(len(lst_wed)):\n",
    "        wednesday_bins.append(list(*[df_wednesday[\"hex_bins\"][0:lst_wed[i]]]))\n",
    "        wednesday_tw.append(list(*[df_wednesday[\"time_window\"][0:lst_wed[i]]]))\n",
    "        thursday_bins.append(list(*[df_thursday[\"hex_bins\"][0:lst_thu[i]]]))\n",
    "        thursday_tw.append(list(*[df_thursday[\"time_window\"][0:lst_thu[i]]]))\n",
    "        friday_bins.append(list(*[df_friday[\"hex_bins\"][0:lst_fri[i]]]))\n",
    "        friday_tw.append(list(*[df_friday[\"time_window\"][0:lst_fri[i]]]))\n",
    "        saturday_bins.append(list(*[df_saturday[\"hex_bins\"][0:lst_sat[i]]]))\n",
    "        saturday_tw.append(list(*[df_saturday[\"time_window\"][0:lst_sat[i]]]))\n",
    "        sunday_bins.append(list(*[df_sunday[\"hex_bins\"][0:lst_sun[i]]]))\n",
    "        sunday_tw.append(list(*[df_sunday[\"time_window\"][0:lst_sun[i]]]))    \n",
    "    \n",
    "    \n",
    "    # Turn list of lists into an overall list for each weekday's predictions\n",
    "    flat_monday_bins = [item for sublist in monday_bins for item in sublist]\n",
    "    flat_monday_tw = [item for sublist in monday_tw for item in sublist]\n",
    "    flat_tuesday_bins = [item for sublist in tuesday_bins for item in sublist]\n",
    "    flat_tuesday_tw = [item for sublist in tuesday_tw for item in sublist]\n",
    "    flat_wednesday_bins = [item for sublist in wednesday_bins for item in sublist]\n",
    "    flat_wednesday_tw = [item for sublist in wednesday_tw for item in sublist]\n",
    "    flat_thursday_bins = [item for sublist in thursday_bins for item in sublist]\n",
    "    flat_thursday_tw = [item for sublist in thursday_tw for item in sublist]\n",
    "    flat_friday_bins = [item for sublist in friday_bins for item in sublist]\n",
    "    flat_friday_tw = [item for sublist in friday_tw for item in sublist]\n",
    "    flat_saturday_bins = [item for sublist in saturday_bins for item in sublist]\n",
    "    flat_saturday_tw = [item for sublist in saturday_tw for item in sublist]\n",
    "    flat_sunday_bins = [item for sublist in sunday_bins for item in sublist]\n",
    "    flat_sunday_tw = [item for sublist in sunday_tw for item in sublist]\n",
    "    \n",
    "    # Generate list with hex bins and time windows as input for prediction\n",
    "    flat_bins = flat_monday_bins + flat_tuesday_bins + flat_wednesday_bins + flat_thursday_bins + flat_friday_bins + flat_saturday_bins + flat_sunday_bins\n",
    "    flat_tw = flat_monday_tw + flat_tuesday_tw + flat_wednesday_tw + flat_thursday_tw + flat_friday_tw + flat_saturday_tw + flat_sunday_tw\n",
    "\n",
    "    # Generate list with day of the week entries for each prediction as input for dataframe\n",
    "    weekdays = [0] * sum(lst_mon) + [1] * sum(lst_tue) + [2] * sum(lst_wed) + [3] * sum(lst_thu) + [4] * sum(lst_fri) + [5] * sum(lst_sat) + [6] * sum(lst_sun)\n",
    "    \n",
    "    # Generate list with week entries for each prediction as input for dataframe\n",
    "    list_of_days_list = [lst_mon, lst_tue, lst_wed, lst_thu, lst_fri, lst_sat, lst_sun]\n",
    "    lst_weeks = []\n",
    "    for lst_days in list_of_days_list:\n",
    "        i = 0\n",
    "        for number in lst_days:\n",
    "            lst_weeks += [i] * number\n",
    "            i += 1\n",
    "    \n",
    "    # Create dataframe\n",
    "    df = pd.DataFrame(list(zip(flat_bins, flat_tw, weekdays, lst_weeks)), columns=[\"hex_bins\", \"time_window\", \"weekday\", \"week\"])\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predicted_rta' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-47-cd473215b5c2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpredictions_c\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgenerate_predictions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdf_cleaned\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredicted_rta\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'predicted_rta' is not defined"
     ]
    }
   ],
   "source": [
    "predictions_c = generate_predictions(df_cleaned, predicted_rta)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reduce_to_time_windows(df):\n",
    "    \"\"\"Takes a data frame of predicted RTA's and brings it into the correct format for clustering.\"\"\"\n",
    "    \n",
    "    # Set start of prediction period\n",
    "    start = pd.to_datetime(\"2019-07-01\")\n",
    "    \n",
    "    # Creates a datetime column that counts the days upwards and then sets all entries to the starting day, 2019-07-01, plus that day\n",
    "    df[\"help\"] = (df[\"week\"]) * 7 + df[\"weekday\"]\n",
    "    df[\"datetime\"] = df[\"help\"].apply(lambda x: start + pd.Timedelta(days=x))\n",
    "    \n",
    "    # Convert time windows strings back to datetime objects and add 1 minute to have them lie inside the time window rather than on the verge\n",
    "    df.loc[df[\"time_window\"] == \"00-03\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(minutes=1)\n",
    "    df.loc[df[\"time_window\"] == \"03-06\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(hours=3, minutes=1)\n",
    "    df.loc[df[\"time_window\"] == \"06-09\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(hours=6, minutes=1)\n",
    "    df.loc[df[\"time_window\"] == \"09-12\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(hours=9, minutes=1)\n",
    "    df.loc[df[\"time_window\"] == \"12-15\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(hours=12, minutes=1)\n",
    "    df.loc[df[\"time_window\"] == \"15-18\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(hours=15, minutes=1)\n",
    "    df.loc[df[\"time_window\"] == \"18-21\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(hours=18, minutes=1)\n",
    "    df.loc[df[\"time_window\"] == \"21-00\", \"datetime\"] = df[\"datetime\"] + pd.Timedelta(hours=21, minutes=1)\n",
    "    \n",
    "    # Remove redundant columns\n",
    "    df = df.drop([\"time_window\", \"weekday\", \"week\", \"help\"], axis=1)\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_for_clustering_c = reduce_to_time_windows(predictions_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_for_clustering_c.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "export_df_to_csv(predictions_for_clustering_c,path_file='../Inputs/predictions_for_clustering_c.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## D. Using weather data and traffic speed data to predict RTA occurrence (yes/no?) per time window and hex_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extend C to also include data that is specific per time window and hex bin. This allows the regression model to output a different value for each time window and hex bin (not only hex bin class)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:nairobi_ambulance] *",
   "language": "python",
   "name": "conda-env-nairobi_ambulance-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
